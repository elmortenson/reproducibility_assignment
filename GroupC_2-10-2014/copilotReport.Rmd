get---
title: "Reproducibility Report"
output:
  html_document:
    toc: true
    toc_float: true
---

# Report Details

```{r}
articleID <- "2-10-2014" # insert the article ID code here e.g., "10-3-2015"
reportType <- 'copilot' # specify whether this is the 'pilot' report or 'copilot' report
pilotNames <- "Elizabeth Mortenson" # insert the pilot's name here e.g., "Tom Hardwicke".
copilotNames <- "Nicky Sullivan" # # insert the co-pilot's name here e.g., "Michael Frank".
pilotTTC <- 650 # insert the pilot's estimated time to complete (in minutes, it is fine to approximate) e.g., 120
copilotTTC <- NA # insert the co-pilot's estimated time to complete (in minutes, it is fine to approximate) e.g., 120
pilotStartDate <- "11/03/2019" # insert the piloting start date in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
copilotStartDate <- as.Date("11/10/19", format = "%m/%d/%y") # insert the co-piloting start date in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
completionDate <- as.Date("11/10/19", format = "%m/%d/%y") # insert the date of final report completion in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
```

------

#### Methods summary: 

Study 1 investigates how accurately participants estimate their future feelings about previous, routine events. At Time 1 (beginning of summer), individuals rated how curious and interested they thought they would be to revisit nine events (e.g., an inside joke, a recent status they had posted on their Facebook profile). Survey responses were used to create a "time-capsule." Three months later, at Time 2 and prior to reviewing their time-capsules, people rated their curiousity before being presented with their answers from Time 1. Next, participants reported their real-time feelings, including levels of surprise, meaningfulness, and interest for each experience (1 = not at all, 7 = extremely). Finally, predicted feelings at Time 1 were compared with those experienced at Time 2. Answers to three constructs--surprise, meaningfulness and interest--were averaged to create a composite interest score. 

------

#### Target outcomes: 

For this article you should focus on the findings reported in the results section for Study 1 (and Table 1).

Specifically, you should attempt to reproduce all descriptive and inferential analyses reported in the text below and associated tables/figures:

Table 1 provides descriptive statistics for each measure for Study 1.

Participants’ Time 1 predictions of their curiosity (M = 3.99, SD = 1.32) were lower than their actual curiosity ratings at Time 2, immediately before reading their responses (M = 4.34, SD = 1.25), t(105) = 2.88, p = .005, d = 0.27. Participants also underestimated how interesting they would find their responses. Predictions of interest at Time 1 (M = 3.54, SD = 1.01) were lower than ratings of actual interest experienced at Time 2 (M = 3.82, SD = 0.89), t(105) = 3.10, p = .003, d = 0.29.

------

```{r global_options, include=FALSE}
# sets up some formatting options for the R Markdown document
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
```

# Step 1: Load packages and prepare report object


```{r}
# load packages
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and export 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(ReproReports) # custom reporting functions
library(psych) # for calculating alphas
library(lsr) # calculating cohen's d
library(rcompanion) #calculating confidence intervals
```


```{r}
# Prepare report object. This will be updated automatically by the reproCheck function each time values are compared
reportObject <- data.frame(dummyRow = TRUE, reportedValue = NA, obtainedValue = NA, valueType = NA, percentageError = NA, comparisonOutcome = NA, eyeballCheck = NA)
```

# Step 2: Load data

```{r}
data <- read_sav("data/Study1_Data.sav")

```

# Step 3: Tidy data

```{r}

#N
data <- data %>%
  filter(!is.na(Order)) # remove NA cases

```
How many participants in the dataset? From the Participants section:

> One hundred thirty-five undergraduates (65.9% female, 33.3% male, 0.7% unreported; mean age = 20.4 years, SD = 1.0) in the northeastern United States completed the first part of this online study in exchange for $5, knowing that they would be contacted later for a follow-up. 

> Three months later, 106 of these students (78.5% response rate; 67.0% female, 32.1% male, 0.9% unreported; mean age = 20.4 years, SD = 1.0) completed a follow-up survey in exchange for an additional $20."

# Step 4: Run analysis

## Pre-processing

```{r}

```

## Descriptive statistics

_Caption from Table 1 (Study 1)_

> Across the nine prompts, participants’ ratings of their curiosity and interest were highly intercorrelated (αcuriosity = .93, αinterest = .90). We therefore present results collapsed across the prompts.

> The values in square brackets are 95% confidence intervals. The table presents results for the composite measure of interest as well as for the specific scales. For the measure of memory, participants indicated how much of their written summary of their conversation they expected to remember at Time 2 or they had remembered at Time 2.

> This column presents p values from t tests comparing predictions with actual experience.


```{r}

#Check alphas before collapsing measures

a.curiosity <- select(data, 1, 5, 9, 13, 17, 21, 25, 29, 33)
a.interest <- select(data, 2, 6, 10, 14, 18, 22, 26, 30, 34)

# Reported curiosity alpha = .93
alpha.c <- alpha(a.curiosity)
alpha.c$total$std.alpha     #Note: variable is the standard alpha (.89) but upper value from my analysis was higher (0.93); not sure how to pull or if needed

# Reported interest alpha = .90
alpha.a <- alpha(a.interest)
alpha.a$total$std.alpha  #Note: variable is is the standard alpha (.86) but upper value from my analysis was higher (0.90); not sure how to pull or if needed

#NS: As Elizabeth pointed out, it looks like for both of their alphas they  have reported the upper bounds of the confidence interval for alpha instead of the standard alpha. While both of the standard alphas are lower than the reported values, the upper bounds are exactly as reported (.93 for curiosity and .90 for interest). I'm not sure whether or not this is correct, so I'll leave it as is for now.

#Running value comparisons on alphas
reportObject <- reproCheck(reportedValue = '.93', obtainedValue = alpha.c$total$std.alpha, valueType = 'coeff')  
reportObject <- reproCheck(reportedValue = '.90', obtainedValue = alpha.a$total$std.alpha, valueType = 'coeff')

```


# Get means and CIs for table
```{r}

#T1 Means/Standard deviations (for Curiosity & Interest Composite only)

#Curiosity T1 mean = 3.99 [3.74, 4.24], SD = 1.32
T1.curious <- groupwiseMean(T1_Curious ~ 1, 
              data   = data, 
              conf   = 0.95, 
              digits = 3)
T1sd.curious <- sd(data$T1_Curious, na.rm = TRUE) # getting SD of T1 curious


#Interest Composite T1 mean = 3.54 [3.34, 3.73], SD = 1.01
T1.interestcomp <- groupwiseMean(T1_Interest_Composite ~ 1, 
              data   = data, 
              conf   = 0.95, 
              digits = 3)
T1sd.interestcomp <- sd(data$T1_Interest_Composite, na.rm = TRUE) # getting SD of T1 interest comp

#Surprise T1 mean = 2.84 [2.64, 3.05]
T1.surprise <- groupwiseMean(T1_Surprised ~ 1, 
              data   = data, 
              conf   = 0.95, 
              digits = 3)

#Meaningfulness T1 mean = 3.81 [3.60, 4.03]
T1.meaningful <- groupwiseMean(T1_Meaningful ~ 1, 
              data   = data, 
              conf   = 0.95, 
              digits = 3)

#Interesting T1 mean = 3.95 [3.73, 4.18]
T1.interest <- groupwiseMean(T1_Interesting ~ 1, 
              data   = data, 
              conf   = 0.95, 
              digits = 3)


#Running value comparisons on T1 means

reportObject <- reproCheck(reportedValue = '3.99', obtainedValue = T1.curious$Mean, valueType = 'mean')
reportObject <- reproCheck(reportedValue = '3.54', obtainedValue = T1.interestcomp$Mean, valueType = 'mean')
reportObject <- reproCheck(reportedValue = '2.84', obtainedValue = T1.surprise$Mean, valueType = 'mean')
reportObject <- reproCheck(reportedValue = '3.81', obtainedValue = T1.meaningful$Mean, valueType = 'mean')
reportObject <- reproCheck(reportedValue = '3.95', obtainedValue = T1.interest$Mean, valueType = 'mean')


#Running value comparisons on T1 SDs

reportObject <- reproCheck(reportedValue = '1.32', obtainedValue = T1sd.curious, valueType = 'sd')
reportObject <- reproCheck(reportedValue = '1.01', obtainedValue = T1sd.interestcomp, valueType = 'sd')


#Running value comparisons on lower T1 CIs

reportObject <- reproCheck(reportedValue = '3.74', obtainedValue = T1.curious$Trad.lower, valueType = 'ci')
reportObject <- reproCheck(reportedValue = '3.34', obtainedValue = T1.interestcomp$Trad.lower, valueType = 'ci')
reportObject <- reproCheck(reportedValue = '2.64', obtainedValue = T1.surprise$Trad.lower, valueType = 'ci')
reportObject <- reproCheck(reportedValue = '3.60', obtainedValue = T1.meaningful$Trad.lower, valueType = 'ci')
reportObject <- reproCheck(reportedValue = '3.73', obtainedValue = T1.interest$Trad.lower, valueType = 'ci')


#Running value comparisons on upper T1 CIs

reportObject <- reproCheck(reportedValue = '4.24', obtainedValue = T1.curious$Trad.upper, valueType = 'ci')
reportObject <- reproCheck(reportedValue = '3.73', obtainedValue = T1.interestcomp$Trad.upper, valueType = 'ci')
reportObject <- reproCheck(reportedValue = '3.05', obtainedValue = T1.surprise$Trad.upper, valueType = 'ci')
reportObject <- reproCheck(reportedValue = '4.03', obtainedValue = T1.meaningful$Trad.upper, valueType = 'ci')
reportObject <- reproCheck(reportedValue = '4.18', obtainedValue = T1.interest$Trad.upper, valueType = 'ci')


#T2 Means/Standard deviations (for Curiosity & Interest Composite only)

#Curiosity T2 mean = 4.34 [4.10, 4.58], SD = 1.25
T2.curious <- groupwiseMean(T2_Curious ~ 1, 
              data   = data, 
              conf   = 0.95, 
              digits = 3)
T2sd.curious <- sd(data$T2_Curious, na.rm = TRUE) # getting SD of T2 curious

#Interest Composite T2 mean = 3.82 [3.65, 4.00], SD = 0.89
T2.interestcomp <- groupwiseMean(T2_Interest_Composite ~ 1, 
              data   = data, 
              conf   = 0.95, 
              digits = 3)
T2sd.interestcomp <- sd(data$T2_Interest_Composite, na.rm = TRUE) # getting SD of interest comp

#Surprise T2 mean = 3.25 [3.06, 3.44]
T2.surprise <- groupwiseMean(T2_Surprised ~ 1, 
              data   = data, 
              conf   = 0.95, 
              digits = 3)

#Meaningfulness T2 mean = 4.04 [3.84, 4.23]
T2.meaningful <- groupwiseMean(T2_Meaningful ~ 1, 
              data   = data, 
              conf   = 0.95, 
              digits = 3)

#Interesting T2 mean = 4.19 [4.00, 4.38]
T2.interest <- groupwiseMean(T2_Interesting ~ 1, 
              data   = data, 
              conf   = 0.95, 
              digits = 3)


#Running value comparisons on T2 means

reportObject <- reproCheck(reportedValue = '4.34', obtainedValue = T2.curious$Mean, valueType = 'mean')
reportObject <- reproCheck(reportedValue = '3.82', obtainedValue = T2.interestcomp$Mean, valueType = 'mean')
reportObject <- reproCheck(reportedValue = '3.25', obtainedValue = T2.surprise$Mean, valueType = 'mean')
reportObject <- reproCheck(reportedValue = '4.04', obtainedValue = T2.meaningful$Mean, valueType = 'mean')
reportObject <- reproCheck(reportedValue = '4.19', obtainedValue = T2.interest$Mean, valueType = 'mean')

#Running value comparisons on T2 SDs

reportObject <- reproCheck(reportedValue = '1.25', obtainedValue = T2sd.curious, valueType = 'sd')
reportObject <- reproCheck(reportedValue = '0.89', obtainedValue = T2sd.interestcomp, valueType = 'sd')

#Running value comparisons on lower T2 CIs

reportObject <- reproCheck(reportedValue = '4.10', obtainedValue = T2.curious$Trad.lower, valueType = 'ci')
reportObject <- reproCheck(reportedValue = '3.65', obtainedValue = T2.interestcomp$Trad.lower, valueType = 'ci')
reportObject <- reproCheck(reportedValue = '3.06', obtainedValue = T2.surprise$Trad.lower, valueType = 'ci')
reportObject <- reproCheck(reportedValue = '3.84', obtainedValue = T2.meaningful$Trad.lower, valueType = 'ci')
reportObject <- reproCheck(reportedValue = '4.00', obtainedValue = T2.interest$Trad.lower, valueType = 'ci')

#Running value comparisons on upper T2 CIs

reportObject <- reproCheck(reportedValue = '4.58', obtainedValue = T2.curious$Trad.upper, valueType = 'ci')
reportObject <- reproCheck(reportedValue = '4.00', obtainedValue = T2.interestcomp$Trad.upper, valueType = 'ci')
reportObject <- reproCheck(reportedValue = '3.44', obtainedValue = T2.surprise$Trad.upper, valueType = 'ci')
reportObject <- reproCheck(reportedValue = '4.23', obtainedValue = T2.meaningful$Trad.upper, valueType = 'ci')
reportObject <- reproCheck(reportedValue = '4.38', obtainedValue = T2.interest$Trad.upper, valueType = 'ci')

#Underestimates

#Curiosity underestimate = 0.35 [0.11, 0.59]
dif.curious <- groupwiseMean(Curious_diff ~ 1, 
              data   = data, 
              conf   = 0.95, 
              digits = 2)

#Interest Composite underestimate = 0.29 [0.10, 0.47]
dif.interestcomp <- groupwiseMean(Interest_composite_diff ~ 1, 
              data   = data, 
              conf   = 0.95, 
              digits = 2)

#Surprise underestimate = 0.40 [0.19, 0.62]
data$Surprised_diff <- data$T2_Surprised - data$T1_Surprised
dif.surprise <- groupwiseMean(Surprised_diff ~ 1, 
              data   = data, 
              conf   = 0.95, 
              digits = 2)

#Meaningfulness underestimate = 0.22 [0.03, 0.42]
data$Meaningful_diff <- data$T2_Meaningful - data$T1_Meaningful
dif.meaningful <- groupwiseMean(Meaningful_diff ~ 1, 
              data   = data, 
              conf   = 0.95, 
              digits = 2)

#Interesting underestimate = 0.23 [0.02, 0.45]
data$Interesting_diff <- data$T2_Interesting - data$T1_Interesting
dif.interest <- groupwiseMean(Interesting_diff ~ 1, 
              data   = data, 
              conf   = 0.95, 
              digits = 2)

#Running value comparisons on underestimate means

reportObject <- reproCheck(reportedValue = '0.35', obtainedValue = dif.curious$Mean, valueType = 'mean')
reportObject <- reproCheck(reportedValue = '0.29', obtainedValue = dif.interestcomp$Mean, valueType = 'mean')
reportObject <- reproCheck(reportedValue = '0.40', obtainedValue = dif.surprise$Mean, valueType = 'mean')
reportObject <- reproCheck(reportedValue = '0.22', obtainedValue = dif.meaningful$Mean, valueType = 'mean')
reportObject <- reproCheck(reportedValue = '0.23', obtainedValue = dif.interest$Mean, valueType = 'mean')


#Running value comparisons on lower underestimate CIs

reportObject <- reproCheck(reportedValue = '0.11', obtainedValue = dif.curious$Trad.lower, valueType = 'ci')
reportObject <- reproCheck(reportedValue = '0.10', obtainedValue = dif.interestcomp$Trad.lower, valueType = 'ci')
reportObject <- reproCheck(reportedValue = '0.19', obtainedValue = dif.surprise$Trad.lower, valueType = 'ci')
reportObject <- reproCheck(reportedValue = '0.03', obtainedValue = dif.meaningful$Trad.lower, valueType = 'ci')
reportObject <- reproCheck(reportedValue = '0.02', obtainedValue = dif.interest$Trad.lower, valueType = 'ci')


#Running value comparisons on upper underestimate CIs

reportObject <- reproCheck(reportedValue = '0.59', obtainedValue = dif.curious$Trad.upper, valueType = 'ci')
reportObject <- reproCheck(reportedValue = '0.47',  obtainedValue = dif.interestcomp$Trad.upper, valueType = 'ci')
reportObject <- reproCheck(reportedValue = '0.62', obtainedValue = dif.surprise$Trad.upper, valueType = 'ci')
reportObject <- reproCheck(reportedValue = '0.42', obtainedValue = dif.meaningful$Trad.upper, valueType = 'ci')
reportObject <- reproCheck(reportedValue = '0.45', obtainedValue = dif.interest$Trad.upper, valueType = 'ci')



#Create vectors for columns (variable, T1 mean/CI, T2 mean/CI, Underestimate)
Measure <- c("curiosity", "interestcomp", "surpise", "meaningful", "interest")

T1Mean <- c(T1.curious$Mean, T1.interestcomp$Mean, T1.surprise$Mean, T1.meaningful$Mean, T1.interest$Mean)

T1LowerCI <- c(T1.curious$Trad.lower, T1.interestcomp$Trad.lower, T1.surprise$Trad.lower, T1.meaningful$Trad.lower, T1.interest$Trad.lower)

T1UpperCI <- c(T1.curious$Trad.upper, T1.interestcomp$Trad.upper, T1.surprise$Trad.upper, T1.meaningful$Trad.upper, T1.interest$Trad.upper)

T2Mean <- c(T2.curious$Mean, T2.interestcomp$Mean, T2.surprise$Mean, T2.meaningful$Mean, T2.interest$Mean)

T2LowerCI <- c(T2.curious$Trad.lower, T2.interestcomp$Trad.lower, T2.surprise$Trad.lower, T2.meaningful$Trad.lower, T2.interest$Trad.lower)

T2UpperCI <- c(T2.curious$Trad.upper, T2.interestcomp$Trad.upper, T2.surprise$Trad.upper, T2.meaningful$Trad.upper, T2.interest$Trad.upper)

Underestimate <- round(c(dif.curious$Mean, dif.interestcomp$Mean, dif.surprise$Mean, dif.meaningful$Mean, dif.interest$Mean), digits = 2)

UndLowerCI <- c(dif.curious$Trad.lower, dif.interestcomp$Trad.lower, dif.surprise$Trad.lower, dif.meaningful$Trad.lower, dif.interest$Trad.lower)

UndUpperCI <- c(dif.curious$Trad.upper, dif.interestcomp$Trad.upper, dif.surprise$Trad.upper, dif.meaningful$Trad.upper, dif.interest$Trad.upper)

```

## Inferential statistics

>Participants’ Time 1 predictions of their curiosity (M = 3.99, SD = 1.32) were lower than their actual curiosity ratings at Time 2, immediately before reading their responses (M = 4.34, SD = 1.25), t(105) = 2.88, p = .005, d = 0.27. Participants also underestimated how interesting they would find their responses. Predictions of interest at Time 1 (M = 3.54, SD = 1.01) were lower than ratings of actual interest experienced at Time 2 (M = 3.82, SD = 0.89), t(105) = 3.10, p = .003, d = 0.29.

```{r}

#Run t-tests 

#Curious t = 2.879981  and  p = 0.004821242
t.curious <- t.test(data$T2_Curious, data$T1_Curious, paired = TRUE)
t.curious$statistic # t for interest comp
t.curious$p.value # p value for curious

#Interesting Composite t = 3.095256  and  p = 0.002521152
t.interestcomp <- t.test(data$T2_Interest_Composite, data$T1_Interest_Composite, paired = TRUE)
t.interestcomp$statistic # t for interest comp
t.interestcomp$p.value # p value for interest comp

# Running value comparisons on t-tests
reportObject <- reproCheck(reportedValue = '2.88', obtainedValue = t.curious$statistic, valueType = 't') # Curious
reportObject <- reproCheck(reportedValue = '3.10', obtainedValue = t.interestcomp$statistic, valueType = 't') # Interest

# Running value comparisons on p-value
reportObject <- reproCheck(reportedValue = '.005', obtainedValue = t.curious$p.value, valueType = 't') # Curious
reportObject <- reproCheck(reportedValue = '.003', obtainedValue = t.interestcomp$p.value, valueType = 't') # Interest

#Calculating Cohen's d

#Cohen's d = 0.30 ******* off by a small bit again
interest.cd <- cohensD(data$T1_Interest_Composite, data$T2_Interest_Composite, method = "paired")
interest.cd.cop <- cohensD(data$T1_Interest_Composite, data$T2_Interest_Composite, method = "corrected")

#Cohen's d = 0.28 ******* actual value 0.2797284... is this incorrect or rounding error?
curiosity.cd <- cohensD(data$T1_Curious, data$T2_Curious, method = "paired")
curiosity.cd.cop <- cohensD(data$T1_Curious, data$T2_Curious, method = "corrected")

#NS: I played around with different methods for calculating Cohen's d, and was unable to get anything that matched for both. If instead of using paired you do pooled or corrected, you get the correct answer (0.27) for the curiosity scores. If you use either of those for the interest scores you still get 0.3 (although if you use corrected it's 0.299, which could be a rounding error). I don't know enough about calculating Cohen's d to know which of these methods they should have used given their data, so I'm leaving these as is for now.

# Running value comparisons on Cohen's d
reportObject <- reproCheck(reportedValue = '0.27', obtainedValue = curiosity.cd, valueType = 'd')
reportObject <- reproCheck(reportedValue = '0.29', obtainedValue = interest.cd, valueType = 'd')

```


#Build a table
```{r}

# Need to get the rest of p-values for the last column

t.surprise <- t.test(data$T1_Surprised, data$T2_Surprised, paired = TRUE)       #Surprise
t.meaningful <- t.test(data$T1_Meaningful, data$T2_Meaningful, paired = TRUE)   #Meaningful
t.interest <- t.test(data$T1_Interesting, data$T2_Interesting, paired = TRUE)   #Interesting

#Significance column
P <- round(c(t.curious$p.value, t.interestcomp$p.value,
                 t.surprise$p.value, t.meaningful$p.value,
                 t.interest$p.value), digits = 3) 

#Create table
table <- kable(cbind(Measure, T1Mean, T1LowerCI, T1UpperCI, T2Mean, T2LowerCI, T2UpperCI, Underestimate, UndLowerCI, UndUpperCI, P))
table

```



# Step 5: Conclusion

This reproducibiity check was a success: majority of the findings (inferential statistics and descriptive values) from the original study were reproduced here with 0% difference and of the four minor errors identified, two were because I wasn't sure how to assign the upper alpha values to a variable, but had I been able to do that they would have reproduced as well. 


```{r}
reportObject <- reportObject %>%
  filter(dummyRow == FALSE) %>% # remove the dummy row
  select(-dummyRow) %>% # remove dummy row designation
  mutate(articleID = articleID) %>% # add variables to report 
  select(articleID, everything()) # make articleID first column

# decide on final outcome
if(any(reportObject$comparisonOutcome %in% c("MAJOR_ERROR", "DECISION_ERROR"))){
  finalOutcome <- "Failure"
}else{
  finalOutcome <- "Success"
}

# collate report extra details
reportExtras <- data.frame(articleID, pilotNames, copilotNames, pilotTTC, copilotTTC, pilotStartDate, copilotStartDate, completionDate, finalOutcome)

# save report objects
if(reportType == "pilot"){
  write_csv(reportObject, "pilotReportDetailed.csv")
  write_csv(reportExtras, "pilotReportExtras.csv")
}

if(reportType == "copilot"){
  write_csv(reportObject, "copilotReportDetailed.csv")
  write_csv(reportExtras, "copilotReportExtras.csv")
}
```

# Session information



[This function will output information about the package versions used in this report:]

```{r session_info, include=TRUE, echo=TRUE, results='markup'}
devtools::session_info()
```
